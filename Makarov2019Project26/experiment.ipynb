{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regression_cascade import *\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--list', default=None)\n",
    "parser.add_argument('--train_test_path', default=None, help='If set, the computed feature vectors, labels and'\n",
    "                                                            'responses will be cached.')\n",
    "parser.add_argument('--output_path', default=None, type=str, help='The path where learned model is written.')\n",
    "parser.add_argument('--subsample', default=1, type=int, help='If greater than 1, the training set will be'\n",
    "                                                             'down-sampled.')\n",
    "parser.add_argument('--step_size', default=10, type=int, help='Number of frame between two feature extractions.')\n",
    "parser.add_argument('--train_ratio', default=0.99999, type=float)\n",
    "parser.add_argument('--cv', default=3, type=int, help='Number of folds during cross-valication.')\n",
    "parser.add_argument('--option', default=None, type=str, help='(Optional) The path to a file containing the '\n",
    "                                                             'hyperparameters. If not provided, a grid search'\n",
    "                                                             ' will be performed to obtain the best hyperparameter.')\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ../../data_publish_v2/zhicheng_leg1/processed/data.csv, type:  leg\n",
      "Loading dataset ../../data_publish_v2/zhicheng_bag1/processed/data.csv, type:  bag\n",
      "Loading dataset ../../data_publish_v2/zhicheng_handheld1/processed/data.csv, type:  handheld\n",
      "Loading dataset ../../data_publish_v2/zhicheng_body1/processed/data.csv, type:  body \n",
      "Data loaded. Total number of samples:  10183\n",
      "2750 samples in  leg(label 0)\n",
      "2476 samples in  bag(label 1)\n",
      "2452 samples in  handheld(label 2)\n",
      "2505 samples in  body (label 3)\n",
      "Randomly splitting the dataset to 10081/102 samples for training/testing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bixind/projects/strizh/ridi_imu/env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "load_from_list = True\n",
    "data_loaded = False\n",
    "feature_train, label_train, responses_train = None, None, None\n",
    "feature_test, label_test, responses_test = None, None, None\n",
    "class_map = {}\n",
    "train_file_path, test_file_path = None, None\n",
    "# if args.train_test_path:\n",
    "#     train_file_path = args.train_test_path + '/train.npy'\n",
    "#     test_file_path = args.train_test_path + '/test.npy'\n",
    "#     if os.path.exists(train_file_path) and os.path.exists(test_file_path) and os.path.exists(\n",
    "#                     args.train_test_path + '/class_map.txt'):\n",
    "#         print('Loading training set from ', train_file_path)\n",
    "#         train_all = np.load(train_file_path)\n",
    "#         print('Loading testing set from ', test_file_path)\n",
    "#         test_all = np.load(test_file_path)\n",
    "#         feature_train, label_train, responses_train = train_all[:, :-3], train_all[:, -3], train_all[:, -2:]\n",
    "#         feature_test, label_test, responses_test = test_all[:, :-3], test_all[:, -3], test_all[:, -2:]\n",
    "#         with open(args.train_test_path + '/class_map.txt') as f:\n",
    "#             num_classes = int(f.readline().strip())\n",
    "#             for i in range(num_classes):\n",
    "#                 line = f.readline().strip().split()\n",
    "#                 class_map[line[0]] = int(line[1])\n",
    "#         load_from_list = False\n",
    "#         data_loaded = True\n",
    "list_path=\"../../data_publish_v2/list_small_train.txt\"\n",
    "if load_from_list:\n",
    "    option = td.TrainingDataOption()\n",
    "    option.sample_step_ = 10 # args.step_size\n",
    "    feature_all, label_all, responses_all, class_map = load_datalist(path=list_path, option=option)\n",
    "    responses_all = responses_all[:, [0, 2]]\n",
    "\n",
    "    print('Data loaded. Total number of samples: ', feature_all.shape[0])\n",
    "\n",
    "    for key, value in class_map.items():\n",
    "        print('%d samples in %s(label %d)' % (len(label_all[label_all==value]), key, value))\n",
    "\n",
    "    # Combine label and response to a single array to simplify the splitting process.\n",
    "    target_temp = np.concatenate([label_all[:, None], responses_all], axis=1)\n",
    "    feature_train, feature_test, target_train, target_test = train_test_split(feature_all, target_temp,\n",
    "                                                                              train_size=0.99)\n",
    "    print('Randomly splitting the dataset to %d/%d samples for training/testing.' %\n",
    "          (feature_train.shape[0], feature_test.shape[0]))\n",
    "    label_train, responses_train = target_train[:, 0], target_train[:, 1:]\n",
    "    label_test, responses_test = target_test[:, 0], target_test[:, 1:]\n",
    "    data_loaded = True\n",
    "#     if args.train_test_path:\n",
    "#         if not os.path.exists(args.train_test_path):\n",
    "#             os.makedirs(args.train_test_path)\n",
    "#         train_all = np.concatenate([feature_train, label_train[:, None], responses_train], axis=1)\n",
    "#         test_all = np.concatenate([feature_test, label_test[:, None], responses_test], axis=1)\n",
    "#         np.save(train_file_path, train_all)\n",
    "#         np.save(test_file_path, test_all)\n",
    "#         with open(args.train_test_path + '/class_map.txt', 'w') as f:\n",
    "#             f.write('%d\\n' % len(class_map))\n",
    "#             for k, v in class_map.items():\n",
    "#                 f.write('{:s} {:d}\\n'.format(k, v))\n",
    "#         print('Training/testing set written to ' + args.train_test_path)\n",
    "if not data_loaded:\n",
    "    raise ValueError('Both data list and train/test directory are invalid')\n",
    "\n",
    "# if args.subsample > 1:\n",
    "#     feature_train = feature_train[0:-1:args.subsample]\n",
    "#     label_train = label_train[0:-1:args.subsample]\n",
    "#     responses_train = responses_train[0:-1:args.subsample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CascadeTemplate:\n",
    "    \"\"\"\n",
    "    The cascaded model consists of a classifier and num_classes * num_channels regressors.\n",
    "    \"\"\"\n",
    "    def __init__(self, classifier, regressor, num_classes, num_channels, class_map):\n",
    "        self.num_classes = num_classes\n",
    "        self.num_channels = num_channels\n",
    "        self.classifier = classifier\n",
    "        self.regressors = [clone(regressor) for i in range(num_classes * num_channels)]\n",
    "        self.class_map = class_map\n",
    "\n",
    "    def train(self, train_feature, train_label, train_response):\n",
    "        \"\"\"\n",
    "        Train the cascade model. It first trains the classifier with train_feature and train_label. Then the\n",
    "        training samples are split into num_classes groups based on train_label. Regressors are trained for each\n",
    "        group and each channel.\n",
    "        \n",
    "        :param train_feature: Nxd array containing N training feature vectors.\n",
    "        :param train_label: Nx1 integer array containing N training labels.\n",
    "        :param train_response: Nxc array where c equals to num_channels.\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        assert train_response.shape[1] == self.num_channels\n",
    "        train_feature_cv = train_feature.astype(np.float32)\n",
    "        if self.num_classes > 1:\n",
    "            print('Training classifier')\n",
    "            self.classifier.fit(train_feature, train_label)\n",
    "            predicted_train = self.classifier.predict(train_feature_cv)\n",
    "            error_svm = accuracy_score(train_label, predicted_train)\n",
    "            print('Classifier trained. Training accuracy: %f' % error_svm)\n",
    "        # Split the training sample based on ground truth label.\n",
    "        for cls_name, cls in self.class_map.items():\n",
    "            feature_in_class = train_feature_cv[train_label == cls, :]\n",
    "            target_in_class = train_response[train_label == cls, :]\n",
    "            # Skip models in 'transition' mode.\n",
    "            if cls_name == ignore_class:\n",
    "                continue\n",
    "            for chn in range(self.num_channels):\n",
    "                rid = cls * self.num_channels + chn\n",
    "                print('Training regressor for class %d, channel %d' % (cls, chn))\n",
    "                self.regressors[rid].fit(feature_in_class,\n",
    "                                         target_in_class[:, chn].astype(np.float32))\n",
    "                predicted = self.regressors[rid].predict(feature_in_class)\n",
    "                print('Regressor for class %d  channel %d trained. Training error: %f(r2), %f(MSE)' %\n",
    "                      (cls, chn, r2_score(predicted, target_in_class[:, chn]),\n",
    "                       mean_squared_error(predicted, target_in_class[:, chn])))\n",
    "        print('All done')\n",
    "\n",
    "    def test(self, test_feature, true_label=None, true_responses=None):\n",
    "        \"\"\"\n",
    "        Predict the label and responses of given samples.\n",
    "        \n",
    "        :param test_feature: Nxd array containing N testing feature vectors.\n",
    "        :param true_label: Optional. Nx1 integer array containing N ground truth label.\n",
    "        :param true_responses: Optional. Nxc array containing N ground truth responses.\n",
    "        :return: predicted label and responses.\n",
    "        \"\"\"\n",
    "        feature_cv = test_feature.astype(np.float32)\n",
    "        labels = np.zeros(feature_cv.shape[0])\n",
    "        if self.num_classes > 1:\n",
    "            labels = self.classifier.predict(feature_cv)\n",
    "            if true_label is not None:\n",
    "                print('Classification accuracy: ', accuracy_score(true_label, labels))\n",
    "\n",
    "        index_array = np.array([i for i in range(test_feature.shape[0])])\n",
    "        reverse_index = [None for _ in self.class_map]\n",
    "        predicted_class = [None for _ in self.class_map]\n",
    "        for cls_name, cls in self.class_map.items():\n",
    "            feature_in_class = feature_cv[labels == cls, :]\n",
    "            predicted_in_class = np.zeros([feature_in_class.shape[0], self.num_channels])\n",
    "            if feature_in_class.shape[0] > 0 and cls_name != ignore_class:\n",
    "                for chn in range(self.num_channels):\n",
    "                    rid = cls * self.num_channels + chn\n",
    "                    predicted_in_class[:, chn] = self.regressors[rid].predict(feature_in_class)\n",
    "            predicted_class[cls] = predicted_in_class\n",
    "            reverse_index[cls] = index_array[labels == cls]\n",
    "        if true_responses is not None:\n",
    "            for cls_name, cls in self.class_map.items():\n",
    "                if cls_name == ignore_class:\n",
    "                    continue\n",
    "                true_in_class = true_responses[labels == cls, :]\n",
    "                if true_in_class.shape[0] == 0:\n",
    "                    continue\n",
    "                for chn in range(self.num_channels):\n",
    "                    mse = mean_squared_error(true_in_class[:, chn], predicted_class[cls][:, chn])\n",
    "                    print('Error for class %d, channel %d: %f(MSE)' % (cls, chn, mse))\n",
    "        predicted_all = np.empty([test_feature.shape[0], self.num_channels])\n",
    "        for cls_name, cls in self.class_map.items():\n",
    "            predicted_all[reverse_index[cls], :] = predicted_class[cls]\n",
    "\n",
    "        if true_responses is not None:\n",
    "            for chn in range(self.num_channels):\n",
    "                mse = mean_squared_error(true_responses[:, chn], predicted_all[:, chn])\n",
    "                print('Overall regression error for channel %d: %f(MSE)' % (chn, mse))\n",
    "        return labels, predicted_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(feature_train, label_train.astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample used for training:  10081\n",
      "Training classifier\n",
      "Classifier trained. Training accuracy: 0.920246\n",
      "Training regressor for class 0, channel 0\n",
      "Regressor for class 0  channel 0 trained. Training error: 0.860663(r2), 0.005970(MSE)\n",
      "Training regressor for class 0, channel 1\n",
      "Regressor for class 0  channel 1 trained. Training error: 0.792729(r2), 0.020685(MSE)\n",
      "Training regressor for class 1, channel 0\n",
      "Regressor for class 1  channel 0 trained. Training error: 0.529064(r2), 0.029316(MSE)\n",
      "Training regressor for class 1, channel 1\n",
      "Regressor for class 1  channel 1 trained. Training error: 0.117832(r2), 0.015405(MSE)\n",
      "Training regressor for class 2, channel 0\n",
      "Regressor for class 2  channel 0 trained. Training error: -20.260236(r2), 0.066690(MSE)\n",
      "Training regressor for class 2, channel 1\n",
      "Regressor for class 2  channel 1 trained. Training error: -0.051769(r2), 0.040288(MSE)\n",
      "Training regressor for class 3, channel 0\n",
      "Regressor for class 3  channel 0 trained. Training error: -1.685126(r2), 0.030228(MSE)\n",
      "Training regressor for class 3, channel 1\n",
      "Regressor for class 3  channel 1 trained. Training error: 0.617430(r2), 0.025265(MSE)\n",
      "All done\n",
      "CPU times: user 8min 34s, sys: 253 ms, total: 8min 34s\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = CascadeTemplate(KNeighborsClassifier(n_neighbors=40), KNeighborsRegressor(n_neighbors=40),\n",
    "                     len(class_map), responses_train.shape[1], class_map)\n",
    "print('Sample used for training: ', feature_train.shape[0])\n",
    "model.train(feature_train, label_train.astype(np.int32), responses_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_list(list_path):\n",
    "    option = td.TrainingDataOption()\n",
    "    option.sample_step_ = 10 # args.step_size\n",
    "    feature_all, label_all, responses_all, class_map = load_datalist(path=list_path, option=option)\n",
    "    responses_all = responses_all[:, [0, 2]]\n",
    "\n",
    "    print('Data loaded. Total number of samples: ', feature_all.shape[0])\n",
    "\n",
    "    for key, value in class_map.items():\n",
    "        print('%d samples in %s(label %d)' % (len(label_all[label_all==value]), key, value))\n",
    "\n",
    "    # Combine label and response to a single array to simplify the splitting process.\n",
    "    target_temp = np.concatenate([label_all[:, None], responses_all], axis=1)\n",
    "    \n",
    "    \n",
    "    label, responses = target_temp[:, 0], target_temp[:, 1:]\n",
    "    return feature_all, label.astype(np.int32), responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset ../../data_publish_v2/ruixuan_leg1/processed/data.csv, type:  leg\n",
      "Loading dataset ../../data_publish_v2/ruixuan_bag1/processed/data.csv, type:  bag\n",
      "Loading dataset ../../data_publish_v2/ruixuan_handheld1/processed/data.csv, type:  handheld\n",
      "Loading dataset ../../data_publish_v2/ruixuan_body2/processed/data.csv, type:  body \n",
      "Data loaded. Total number of samples:  9317\n",
      "2802 samples in  leg(label 0)\n",
      "2547 samples in  bag(label 1)\n",
      "2694 samples in  handheld(label 2)\n",
      "1274 samples in  body (label 3)\n"
     ]
    }
   ],
   "source": [
    "feature_val, label_val, responses_val = read_list(\"../../data_publish_v2/list_small_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.15656441, -0.62959046])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses_val.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy:  0.4132231404958678\n",
      "Error for class 0, channel 0: 0.070734(MSE)\n",
      "Error for class 0, channel 1: 0.123183(MSE)\n",
      "Error for class 1, channel 0: 0.096159(MSE)\n",
      "Error for class 1, channel 1: 0.015070(MSE)\n",
      "Error for class 2, channel 0: 0.482002(MSE)\n",
      "Error for class 2, channel 1: 0.786707(MSE)\n",
      "Error for class 3, channel 0: 0.101943(MSE)\n",
      "Error for class 3, channel 1: 0.074792(MSE)\n",
      "Overall regression error for channel 0: 0.417886(MSE)\n",
      "Overall regression error for channel 1: 0.675967(MSE)\n",
      "CPU times: user 2.73 s, sys: 100 ms, total: 2.83 s\n",
      "Wall time: 2.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_labels, res_predicted = model.test(feature_val, label_val, responses_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done\n"
     ]
    }
   ],
   "source": [
    "def stuff():\n",
    "    svm_option = SVMOption()\n",
    "    svm_option.svm_type = cv2.ml.SVM_C_SVC\n",
    "    svm_option.kernel_type = cv2.ml.SVM_RBF\n",
    "    svm_option.C = 10.0\n",
    "    svm_option.gamma = 1. / feature_train.shape[1]\n",
    "\n",
    "    svr_options = []\n",
    "    num_classes = max(label_train) + 1\n",
    "    assert num_classes == len(class_map)\n",
    "    num_channels = responses_train.shape[1]\n",
    "    for cls_name, cls in class_map.items():\n",
    "        for chn in range(num_channels):\n",
    "            svr_option = SVMOption()\n",
    "            svr_option.svm_type = cv2.ml.SVM_EPS_SVR\n",
    "            svr_option.kernel_type = cv2.ml.SVM_RBF\n",
    "            svr_option.gamma = 1. / feature_train.shape[1]\n",
    "            if cls_name is not ignore_class:\n",
    "                svr_option.C = 1\n",
    "                svr_option.e = 0.01\n",
    "            svr_options.append(svr_option)\n",
    "    print('All done')\n",
    "    return SVRCascadeOption(num_classes, num_channels, svm_option, svr_options)\n",
    "option = stuff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample used for training:  10081\n",
      "Training classifier\n",
      "Classifier trained. Training accuracy: 0.991271\n",
      "Training regressor for class 0, channel 0\n",
      "Regressor for class 0  channel 0 trained. Training error: 0.997724(r2), 0.000102(MSE)\n",
      "Training regressor for class 0, channel 1\n",
      "Regressor for class 0  channel 1 trained. Training error: 0.998848(r2), 0.000114(MSE)\n",
      "Training regressor for class 1, channel 0\n",
      "Regressor for class 1  channel 0 trained. Training error: 0.998039(r2), 0.000127(MSE)\n",
      "Training regressor for class 1, channel 1\n",
      "Regressor for class 1  channel 1 trained. Training error: 0.996128(r2), 0.000102(MSE)\n",
      "Training regressor for class 2, channel 0\n",
      "Regressor for class 2  channel 0 trained. Training error: 0.342953(r2), 0.020653(MSE)\n",
      "Training regressor for class 2, channel 1\n",
      "Regressor for class 2  channel 1 trained. Training error: 0.422518(r2), 0.022804(MSE)\n",
      "Training regressor for class 3, channel 0\n",
      "Regressor for class 3  channel 0 trained. Training error: 0.997741(r2), 0.000101(MSE)\n",
      "Training regressor for class 3, channel 1\n",
      "Regressor for class 3  channel 1 trained. Training error: 0.997180(r2), 0.000187(MSE)\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "bmodel = SVRCascade(option, class_map)\n",
    "print('Sample used for training: ', feature_train.shape[0])\n",
    "bmodel.train(feature_train, label_train.astype(np.int32), responses_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy:  0.9541697971450037\n",
      "Error for class 0, channel 0: 0.045992(MSE)\n",
      "Error for class 0, channel 1: 0.037454(MSE)\n",
      "Error for class 1, channel 0: 0.017859(MSE)\n",
      "Error for class 1, channel 1: 0.019767(MSE)\n",
      "Error for class 2, channel 0: 0.042062(MSE)\n",
      "Error for class 2, channel 1: 0.036382(MSE)\n",
      "Error for class 3, channel 0: 0.044325(MSE)\n",
      "Error for class 3, channel 1: 0.016320(MSE)\n",
      "Overall regression error for channel 0: 0.037335(MSE)\n",
      "Overall regression error for channel 1: 0.029780(MSE)\n",
      "CPU times: user 3min 45s, sys: 113 ms, total: 3min 45s\n",
      "Wall time: 28.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res_labels, res_predicted = bmodel.test(feature_val, label_val, responses_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
